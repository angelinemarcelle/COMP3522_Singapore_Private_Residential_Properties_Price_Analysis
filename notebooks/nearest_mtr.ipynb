{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c406e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ffdb4450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9b17bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates(project_name):\n",
    "    \"\"\"Get coordinates from OneMap API for a given project name\"\"\"\n",
    "    base_url = \"https://www.onemap.gov.sg/api/common/elastic/search\"\n",
    "    headers = {\"Authorization\": \"Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjo4OTgyLCJmb3JldmVyIjpmYWxzZSwiaXNzIjoiT25lTWFwIiwiaWF0IjoxNzU4NzA5MDY0LCJuYmYiOjE3NTg3MDkwNjQsImV4cCI6MTc1ODk2ODI2NCwianRpIjoiZDJiMGI0ZDktZjUwMi00NzlkLTg1MGQtNjMxZThkNTg1YWE0In0.Zx3mwVumXn7b06tPDpViZEwM_UPV3vH57T_F85v0RZL9bU3Pkr1SeHp2U2E0mgzWeRSO5e-lfT2PmHvw5Abn8E-X3V0brG5Ke9QJNjsaaKocOQuTXKoabS4_X2-GN7GkGPPr5-IFR5braFhTHzZfFmC2vwDwEP6IDYkURV8NuzjmT8yLX29l_gVkiQPxI1_3MPYahDT0sb1IXTRjAmP6R6RGVtVfnQTI1splQxcfNZguY3u4l441caafnoJo101kcFaXLAKo4d2V0EqoN1aKph92wHjbIkFioF-0d_8JGLgshMuHSm2KsI1IpruMnR-x7M1bKkYFSybszg7KuszN_A\"}\n",
    "\n",
    "    \n",
    "    try:\n",
    "        # Clean project name\n",
    "        project_name = str(project_name).strip()\n",
    "        \n",
    "        # Parameters for the API call\n",
    "        params = {\n",
    "            'searchVal': project_name,\n",
    "            'returnGeom': 'Y',\n",
    "            'getAddrDetails': 'Y'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(base_url, params=params, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data['found'] > 0:\n",
    "                result = data['results'][0]\n",
    "                return float(result['LATITUDE']), float(result['LONGITUDE']), str(result['ADDRESS'])\n",
    "        \n",
    "        return None, None, None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {project_name}: {str(e)}\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25d39f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coordinates for each historical data district dataset\n",
    "for district_num in range(25, 29):\n",
    "    # Read the existing dataset\n",
    "    df = pd.read_csv(f'../datasets/historical_datasets/district{district_num}.csv', encoding='latin1')\n",
    "\n",
    "    # Create new columns for coordinates\n",
    "    df['Latitude'] = None\n",
    "    df['Longitude'] = None\n",
    "    df['Full Address'] = None\n",
    "\n",
    "    # Process each unique project name\n",
    "    for project_name in df['Project Name'].unique():\n",
    "        print(f\"Processing: {project_name}\")\n",
    "        lat, lon, address = get_coordinates(project_name)\n",
    "        \n",
    "        # Update all rows with this project name\n",
    "        if lat is not None and lon is not None:\n",
    "            df.loc[df['Project Name'] == project_name, 'Latitude'] = lat\n",
    "            df.loc[df['Project Name'] == project_name, 'Longitude'] = lon\n",
    "            df.loc[df['Project Name'] == project_name, 'Full Address'] = address\n",
    "\n",
    "        \n",
    "        # Add delay to avoid hitting API rate limits\n",
    "        time.sleep(1)\n",
    "\n",
    "    # Save the updated dataset\n",
    "    df.to_csv(f'../datasets/updated_coordinates/district{district_num}.csv', index=False)\n",
    "    print(\"Updated dataset saved with coordinates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "08f3472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_property_name(name):\n",
    "    # Convert to string in case of non-string input\n",
    "    name = str(name)\n",
    "    \n",
    "    # Remove emojis and special characters\n",
    "    name = re.sub(r'[^\\x00-\\x7F]+', '', name)  # Remove non-ASCII characters\n",
    "    name = re.sub(r'[⭐★☆✨]+', '', name)  # Remove star symbols\n",
    "    \n",
    "    # Remove common advertising phrases\n",
    "    ad_phrases = [\n",
    "        r'!!!.*!!!',\n",
    "        r'CHEAPER.*BAY',\n",
    "        r'LOW ENTRY.*VIEWS',\n",
    "        r'LUXURY LIVING.*',\n",
    "        r'CHEAP.*',\n",
    "        r'UNBLOCK.*VIEW.*',\n",
    "        r'UNDERVALUED.*',\n",
    "        r'Brand New Condos.*',\n",
    "        r'Developer Sale.*',\n",
    "        r'NEW Condo.*',\n",
    "        r'^!!!.*',\n",
    "        r'.*!!!$'\n",
    "    ]\n",
    "    \n",
    "    for phrase in ad_phrases:\n",
    "        name = re.sub(phrase, '', name, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Remove leading/trailing special characters and whitespace\n",
    "    name = re.sub(r'^[-!@#$%^&*(),.?\":{}|<> ]+|[-!@#$%^&*(),.?\":{}|<> ]+$', '', name)\n",
    "    \n",
    "    # Remove multiple spaces\n",
    "    name = re.sub(r'\\s+', ' ', name)\n",
    "    \n",
    "    # If name becomes empty after cleaning, return None\n",
    "    if not name.strip():\n",
    "        return None\n",
    "        \n",
    "    return name.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0424655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coordinates for each current listing district dataset\n",
    "for district_num in range(1, 29):\n",
    "    # Read the existing dataset\n",
    "    df = pd.read_csv(f'../scrapers/data/Sep2025/condo-sales-{district_num}-Sep2025.csv', encoding='latin1')\n",
    "\n",
    "    # Create new columns for coordinates\n",
    "    df['Latitude'] = None\n",
    "    df['Longitude'] = None\n",
    "    df['Full Address'] = None\n",
    "\n",
    "    # Process each unique project name\n",
    "    for project_name in df['PropertyName'].unique():\n",
    "        project_name = clean_property_name(project_name)\n",
    "        if project_name is None:\n",
    "            continue\n",
    "        print(f\"Processing: {project_name}\")\n",
    "        lat, lon, address = get_coordinates(project_name)\n",
    "        \n",
    "        # Update all rows with this project name\n",
    "        if lat is not None and lon is not None:\n",
    "            df.loc[df['PropertyName'] == project_name, 'Latitude'] = lat\n",
    "            df.loc[df['PropertyName'] == project_name, 'Longitude'] = lon\n",
    "            df.loc[df['PropertyName'] == project_name, 'Full Address'] = address\n",
    "\n",
    "        # Add delay to avoid hitting API rate limits\n",
    "        time.sleep(1)\n",
    "\n",
    "    # Save the updated dataset\n",
    "    df.to_csv(f'../scrapers/data/Sep2025/updated_coordinates/district{district_num}_current_listings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933236d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_mrt_stations(project_name, latitude, longitude):\n",
    "    \"\"\"Get coordinates from OneMap API for a given project name\"\"\"\n",
    "    base_url = \"https://www.onemap.gov.sg/api/public/nearbysvc/getNearestMrtStops\"\n",
    "    headers = {\"Authorization\": \"Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjo4OTgyLCJmb3JldmVyIjpmYWxzZSwiaXNzIjoiT25lTWFwIiwiaWF0IjoxNzU4NzA5MDY0LCJuYmYiOjE3NTg3MDkwNjQsImV4cCI6MTc1ODk2ODI2NCwianRpIjoiZDJiMGI0ZDktZjUwMi00NzlkLTg1MGQtNjMxZThkNTg1YWE0In0.Zx3mwVumXn7b06tPDpViZEwM_UPV3vH57T_F85v0RZL9bU3Pkr1SeHp2U2E0mgzWeRSO5e-lfT2PmHvw5Abn8E-X3V0brG5Ke9QJNjsaaKocOQuTXKoabS4_X2-GN7GkGPPr5-IFR5braFhTHzZfFmC2vwDwEP6IDYkURV8NuzjmT8yLX29l_gVkiQPxI1_3MPYahDT0sb1IXTRjAmP6R6RGVtVfnQTI1splQxcfNZguY3u4l441caafnoJo101kcFaXLAKo4d2V0EqoN1aKph92wHjbIkFioF-0d_8JGLgshMuHSm2KsI1IpruMnR-x7M1bKkYFSybszg7KuszN_A\"}\n",
    "\n",
    "    \n",
    "    try:\n",
    "        # Parameters for the API call\n",
    "        params = {\n",
    "            'latitude': latitude,\n",
    "            'longitude': longitude,\n",
    "            'radius_in_meters': '1000'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(base_url, params=params, headers=headers)\n",
    "        \n",
    "        stations = []\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data:\n",
    "                # Extract station names and distances\n",
    "                stations = [station['name'] for station in data]\n",
    "                return \"; \".join(stations)\n",
    "            else:\n",
    "                return None\n",
    "        \n",
    "        return f\"API Error: {response.status_code}\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {project_name}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbefa8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for district_num in range(15, 29):\n",
    "    try:        \n",
    "        # Read the updated dataset\n",
    "        df = pd.read_csv(f'../datasets/updated_coordinates/district{district_num}.csv')\n",
    "\n",
    "        # Filter out rows without coordinates\n",
    "        df = df.dropna(subset=['Latitude', 'Longitude'])\n",
    "\n",
    "        # Create new column for MRT stations if it doesn't exist\n",
    "        if 'Nearest MRT Stations' not in df.columns:\n",
    "            df['Nearest MRT Stations'] = None\n",
    "\n",
    "        # Process each unique project\n",
    "        for project_name in df['Project Name'].unique():\n",
    "            try:\n",
    "                # Get the first row for this project (assuming coordinates are same for same project)\n",
    "                project_row = df[df['Project Name'] == project_name].iloc[0]\n",
    "                \n",
    "                print(f\"Processing: {project_name}\")\n",
    "                                \n",
    "                # Get nearest MRT stations\n",
    "                mrt_stations = get_nearest_mrt_stations(\n",
    "                    project_name,\n",
    "                    str(project_row['Latitude']),  # Convert to string\n",
    "                    str(project_row['Longitude'])  # Convert to string\n",
    "                )\n",
    "                \n",
    "                # Update all rows for this project\n",
    "                df.loc[df['Project Name'] == project_name, 'Nearest MRT Stations'] = mrt_stations\n",
    "                \n",
    "                # Add delay to avoid hitting API rate limits\n",
    "                time.sleep(0.5)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {project_name} in district {district_num}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        # Save the updated dataset\n",
    "        df.to_csv(f'../datasets/updated_coordinates/district{district_num}.csv', index=False)\n",
    "        print(f\"Completed district {district_num}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing district {district_num}: {str(e)}\")\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs484",
   "language": "python",
   "name": "cs484"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
